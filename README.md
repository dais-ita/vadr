# Visual & Acoustic Discriminative Relevance for Activity Recognition
[![Conference](http://img.shields.io/badge/BMVA_Symposium_on_Video_Understanding-2019-blue.svg?style=flat-square)](https://dimadamen.github.io/bmva_symposium_2019/)

This repository holds experiment code for Visual & Acoustic Discriminative Relevance (VADR) demonstrated on the UCF-101 action recognition dataset.

The model architecture used is a concatenated fusion of VGGish and C3D at the layer before the bottleneck, with a simple MLP for classification of actions.

